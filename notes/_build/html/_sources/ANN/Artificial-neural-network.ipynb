{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22ce0d2",
   "metadata": {},
   "source": [
    "## Artificial neuron networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be7de7",
   "metadata": {},
   "source": [
    "An artificial neural network seek to model how our brain process information. This is useful since our brain is good at tasks computers can't do. For example, almost instantly from birth, a baby can recognize the face of father and mother. For a computer, however, this is a nontrivial task. <br>\n",
    "\n",
    "The brain contains around 10 billion neurons, and each neuron is connected to other neurons through 10000 synapses. Essentially, a brain can be thought as a massive parallel computer that can perform parallel computations extremely efficiently. <br>\n",
    "\n",
    "In 1943 Warren S. McCulloch and Walter Pitts, a neuroscientist and a logiciann desgined the first artificial neuron. It seeks to model the action potential in biological neurons. <br>\n",
    "\n",
    "This computing units takes in inputs $x_1, x_2$ and summed them $x_1+x_2$. The neuron then decides whether to fire a signal $y$ by asking whether $x_1+x_2$ is above the threshold $\\theta$. Mathematically, the output $y$ is given by \n",
    "\n",
    "$$y=\\begin{cases} 1\\;\\;\\;\\;\\;\\;\\;\\text{if}\\;x_1+x_2\\geq \\theta\\\\\n",
    "0\\;\\;\\;\\;\\;\\;\\;\\text{otherwise}\\end{cases}$$\n",
    "\n",
    "The McCulloch Pitts neuron is able to perform basic computation. To see this, note that it can model both a OR and AND gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23617ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def McCullochPittsNeuron(theta):\n",
    "    def neuron(x1, x2):\n",
    "        if x1 + x2 >= theta:\n",
    "            return 1\n",
    "        return 0\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d1bb7",
   "metadata": {},
   "source": [
    "We can design an AND gate by specifying $\\theta=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "621097b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "AND_gate = McCullochPittsNeuron(theta=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46032d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed in inputs 0 and 0, returned 0\n",
      "Passed in inputs 1 and 0, returned 0\n",
      "Passed in inputs 0 and 1, returned 0\n",
      "Passed in inputs 1 and 1, returned 1\n"
     ]
    }
   ],
   "source": [
    "inputs = [(0, 0), (1, 0), (0, 1), (1, 1)]\n",
    "for i in inputs:\n",
    "    print(f\"Passed in inputs {i[0]} and {i[1]}, returned {AND_gate(i[0], i[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea37d42",
   "metadata": {},
   "source": [
    "We can also design an OR gate by letting $\\theta=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5a837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_gate = McCullochPittsNeuron(theta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3230cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed in inputs 0 and 0, returned 0\n",
      "Passed in inputs 1 and 0, returned 1\n",
      "Passed in inputs 0 and 1, returned 1\n",
      "Passed in inputs 1 and 1, returned 1\n"
     ]
    }
   ],
   "source": [
    "inputs = [(0, 0), (1, 0), (0, 1), (1, 1)]\n",
    "for i in inputs:\n",
    "    print(f\"Passed in inputs {i[0]} and {i[1]}, returned {OR_gate(i[0], i[1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f70e4b",
   "metadata": {},
   "source": [
    "It is then a natural question to ask whether McCulloch Pitts neuron is able to model every gate. Unfortunately, this is not the case, since it only generates linear boundary. Note that given fixed $\\theta^*$, we classify points based on the decision boundary\n",
    "\n",
    "$$ x_1+x_2=\\theta^*$$\n",
    "\n",
    "And therefore it is unable to model XOR gate, which is not linearly separable. This motivates the following generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9e4917",
   "metadata": {},
   "source": [
    "### Simple perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c55dd",
   "metadata": {},
   "source": [
    "A generalization of McCulloch Pitts neuron is the perceptron. Instead of simply adding the inputs, it considers the linear combinations of these inputs. Mathematically,\n",
    "\n",
    "$$y=\\begin{cases} 1\\;\\;\\;\\;\\;\\;\\;\\text{if}\\;w_1x_1+w_2x_2+b\\geq 0\\\\\n",
    "0\\;\\;\\;\\;\\;\\;\\;\\text{otherwise}\\end{cases}$$\n",
    "\n",
    "Where $w_1, w_2, b$ are trainable parameters. Even though a simple perceptron has more flexibility compared to McCoulloch Pitts neuron, it still generates linear decision boundary:\n",
    "\n",
    "$$w_1x_2+w_2x_2+b=0$$\n",
    "\n",
    "In classification tasks, the weights of a simple perceptron can be determined by using the perceptron algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bec7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_perceptron(w1, w2, b):\n",
    "    def neuron(x1, x2):\n",
    "        if w1*x1 + w2*x2 + b >= 0:\n",
    "            return 1\n",
    "        return 0\n",
    "    return neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a858cff",
   "metadata": {},
   "source": [
    "### Multilayer perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751354e",
   "metadata": {},
   "source": [
    "By stacking multiple perceptrons, however, we are able to generate nonlinear decision boundaries. Consider the following example of modeling the XOR gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0698618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_gate(x1, x2):\n",
    "    perceptron1 = single_perceptron(1, 1, -1.5)\n",
    "    perceptron2 = single_perceptron(1, 1, -0.5)\n",
    "    perceptron3 = single_perceptron(-1, 1, -0.5)\n",
    "    h1 = perceptron1(x1, x2)\n",
    "    h2 = perceptron2(x1, x2)\n",
    "    y = perceptron3(h1, h2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4626ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed in inputs 0 and 0, returned 0\n",
      "Passed in inputs 1 and 0, returned 1\n",
      "Passed in inputs 0 and 1, returned 1\n",
      "Passed in inputs 1 and 1, returned 0\n"
     ]
    }
   ],
   "source": [
    "inputs = [(0, 0), (1, 0), (0, 1), (1, 1)]\n",
    "for i in inputs:\n",
    "    print(f\"Passed in inputs {i[0]} and {i[1]}, returned {XOR_gate(i[0], i[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716926d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
